# plugins/word_frequency/__init__.py
"""
Plugin de an√°lise que calcula frequ√™ncia de palavras
"""

from typing import Dict, Any, Set
import re
from collections import Counter

# IMPORTS CORRETOS - incluir TUDO que precisa!
from qualia.core import BaseAnalyzerPlugin
from qualia.core import PluginMetadata, PluginType, Document

class WordFrequencyAnalyzer(BaseAnalyzerPlugin):
    """
    Analisa frequ√™ncia de palavras em documentos
    CIRCUIT BREAKER AUTOM√ÅTICO! üõ°Ô∏è
    """
    
    def meta(self) -> PluginMetadata:
        """Metadados do plugin - OBRIGAT√ìRIO"""
        return PluginMetadata(
            id="word_frequency",
            name="Word Frequency Analyzer", 
            type=PluginType.ANALYZER,
            version="1.0.0",
            description="Calcula frequ√™ncia de palavras em documentos",
            requires=[],  # N√£o depende de outros plugins
            provides=["word_frequencies", "total_words", "unique_words"],
            parameters={
                "min_length": {
                    "type": "integer",
                    "default": 3,
                    "description": "Tamanho m√≠nimo da palavra"
                },
                "max_words": {
                    "type": "integer", 
                    "default": 100,
                    "description": "N√∫mero m√°ximo de palavras no resultado"
                },
                "exclude_stopwords": {
                    "type": "boolean",
                    "default": True,
                    "description": "Excluir palavras comuns (stopwords)"
                },
                "case_sensitive": {
                    "type": "boolean",
                    "default": False,
                    "description": "Diferenciar mai√∫sculas e min√∫sculas"
                }
            }
        )
    
    def _analyze_impl(self, document: Document, config: Dict[str, Any], 
                      context: Dict[str, Any]) -> Dict[str, Any]:
        """
        L√ìGICA PURA DO PLUGIN! üéØ
        Circuit breaker j√° protege automaticamente!
        """
        text = document.content
        
        # Normalizar case se necess√°rio
        if not config['case_sensitive']:
            text = text.lower()
        
        # Extrair palavras (regex simples)
        words = re.findall(r'\b[a-z√°√†√¢√£√§√©√®√™√´√≠√¨√Æ√Ø√≥√≤√¥√µ√∂√∫√π√ª√º√ß√±]+\b', text, re.IGNORECASE)
        
        # Filtrar por tamanho m√≠nimo
        words = [word for word in words if len(word) >= config['min_length']]
        
        # Excluir stopwords se configurado
        if config['exclude_stopwords']:
            stopwords = self._get_stopwords()
            words = [word for word in words if word not in stopwords]
        
        # Contar frequ√™ncias
        word_freq = Counter(words)
        
        # Limitar n√∫mero de palavras
        most_common = word_freq.most_common(config['max_words'])
        
        # Retornar resultados
        return {
            "word_frequencies": dict(most_common),
            "total_words": len(words),
            "unique_words": len(word_freq),
            "top_words": [word for word, count in most_common[:10]]
        }
    
    def _get_stopwords(self) -> Set[str]:
        """Retorna set de stopwords em portugu√™s"""
        return {
            'a', '√†', 'ao', 'aos', 'as', '√†', 'e', '√©', 'o', 'os', 'da', 'das', 'de', 
            'do', 'dos', 'em', 'na', 'nas', 'no', 'nos', 'para', 'por', 'com', 'sem',
            'que', 'se', 'como', 'mais', 'mas', 'muito', 'muito', 'bem', 'j√°', 'n√£o',
            'um', 'uma', 'uns', 'umas', 'ele', 'ela', 'eles', 'elas', 'eu', 'tu', 
            'voc√™', 'n√≥s', 'v√≥s', 'voc√™s', 'meu', 'minha', 'meus', 'minhas', 'seu',
            'sua', 'seus', 'suas', 'nosso', 'nossa', 'nossos', 'nossas', 'este',
            'esta', 'estes', 'estas', 'esse', 'essa', 'esses', 'essas', 'aquele',
            'aquela', 'aqueles', 'aquelas', 'que', 'qual', 'quais', 'quando', 'onde',
            'como', 'porque', 'por', 'que', 'ent√£o', 'assim', 'tamb√©m', 'ainda',
            'sobre', 'entre', 'at√©', 'depois', 'antes', 'agora', 'hoje', 'ontem',
            'amanh√£', 'sempre', 'nunca', '√†s', 'vezes', 'pode', 'poder', 'tem',
            'ter', 'vai', 'ir', 'vou', 'foi', 'ser', 'estar', 'sendo', 'estando'
        }

# Exportar plugin
__all__ = ['WordFrequencyAnalyzer']